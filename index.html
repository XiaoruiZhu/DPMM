<!DOCTYPE html>
<html>
<head>
  <title>Dirichlet Process Mixture Models</title>
  <meta charset="utf-8">
  <meta name="description" content="Dirichlet Process Mixture Models">
  <meta name="author" content="Xiaorui Zhu (Joint work with Brittany Green)">
  <meta name="generator" content="slidify" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <link rel="stylesheet" href="libraries/frameworks/io2012/css/default.css" media="all" >
  <link rel="stylesheet" href="libraries/frameworks/io2012/css/phone.css" 
    media="only screen and (max-device-width: 480px)" >
  <link rel="stylesheet" href="libraries/frameworks/io2012/css/slidify.css" >
  <link rel="stylesheet" href="libraries/highlighters/highlight.js/css/tomorrow.css" />
  <base target="_blank"> <!-- This amazingness opens all links in a new tab. -->  <link rel=stylesheet href="libraries/widgets/bootstrap/css/bootstrap.css"></link>
<link rel=stylesheet href="libraries/widgets/quiz/css/demo.css"></link>
<link rel=stylesheet href="libraries/widgets/interactive/css/aceeditor.css"></link>
<link rel=stylesheet href="libraries/widgets/nvd3/css/nv.d3.css"></link>
<link rel=stylesheet href="libraries/widgets/nvd3/css/rNVD3.css"></link>
<link rel=stylesheet href="./assets/css/ribbons.css"></link>

  
  <!-- Grab CDN jQuery, fall back to local if offline -->
  <script src="http://ajax.aspnetcdn.com/ajax/jQuery/jquery-1.7.min.js"></script>
  <script>window.jQuery || document.write('<script src="libraries/widgets/quiz/js/jquery.js"><\/script>')</script> 
  <script data-main="libraries/frameworks/io2012/js/slides" 
    src="libraries/frameworks/io2012/js/require-1.0.8.min.js">
  </script>
  
  <script src="libraries/widgets/nvd3/js/jquery-1.8.2.min.js"></script>
<script src="libraries/widgets/nvd3/js/d3.v3.min.js"></script>
<script src="libraries/widgets/nvd3/js/nv.d3.min-new.js"></script>
<script src="libraries/widgets/nvd3/js/fisheye.js"></script>
<script src="libraries/widgets/highcharts/js/jquery-1.9.1.min.js"></script>
<script src="libraries/widgets/highcharts/js/highcharts.js"></script>
<script src="libraries/widgets/highcharts/js/highcharts-more.js"></script>
<script src="libraries/widgets/highcharts/js/exporting.js"></script>


</head>
<body style="opacity: 0">
  <slides class="layout-widescreen">
    
    <!-- LOGO SLIDE -->
        <slide class="title-slide segue nobackground">
  <aside class="gdbar">
    <img src="assets/img/logo.png">
  </aside>
  <hgroup class="auto-fadein">
    <h1>Dirichlet Process Mixture Models</h1>
    <h2>Models and Inferences</h2>
    <p>Xiaorui Zhu (Joint work with Brittany Green)<br/>Ph.D. students in Business Analytics</p>
  </hgroup>
  <article></article>  
</slide>
    

    <!-- SLIDES -->
    <slide class="" id="slide-1" style="background:;">
  <article data-timings="">
    
  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-2" style="background:;">
  <hgroup>
    <h2>Storyline</h2>
  </hgroup>
  <article data-timings="">
    <ol>
<li>Motivation</li>
<li>Dirichlet Process Mixture Models</li>
<li>Gibbs Sampling Algorithm</li>
<li>Simulation results</li>
</ol>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-3" style="background:;">
  <hgroup>
    <h2>Motivation</h2>
  </hgroup>
  <article data-timings="">
    <p>Truth is complicated:
<center><img width=400px height=400px src="figure/OB_HIST.png" align="left"></img>
</center></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-4" style="background:;">
  <hgroup>
    <h2>Motivation</h2>
  </hgroup>
  <article data-timings="">
    <p>Truth is complicated:
<center><img width=400px height=400px src="figure/OB_HIST.png" align="left"></img>
<img width=400px height=400px src="figure/DPMM_HIST.png" align="right"></img>
</center></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-5" style="background:;">
  <hgroup>
    <h2>Motivation</h2>
  </hgroup>
  <article data-timings="">
    <p>Truth is complicated:
<center><img width=400px height=400px src="figure/OB_HIST_2D.png" align="left"></img>
</center></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-6" style="background:;">
  <hgroup>
    <h2>Motivation</h2>
  </hgroup>
  <article data-timings="">
    <p>Truth is complicated:
<center><img width=400px height=400px src="figure/OB_HIST_2D.png" align="left"></img>
<img width=400px height=400px src="figure/DPMM_HIST_2D.png" align="right"></img>
</center></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-7" style="background:;">
  <hgroup>
    <h2>Dirichlet Process Mixture Model</h2>
  </hgroup>
  <article data-timings="">
    <p>\(DP\) is a random measure defined as: \[\mu = \sum^{\infty}_{i=1} p_i \delta_{\phi_i}, \] where:</p>

<ul>
<li>\((p_n)_{n\in N}\) are random weights by stick-breaking construction with parameter \(\theta\)</li>
<li>and \(G_0\) is &quot;the base measure&quot;</li>
</ul>

<p>Therefore, \(\mu \sim DP(\theta, G_0)\) has following repressentation: </p>

<p>\[\begin{array}
  {rl}
  \mu & = \;  \displaystyle \sum^{\infty}_{i=1} \Big[ V_i \prod^{i-1}_{j=1}(1-V_j) \Big] \delta_{\phi_i} \\
  V_i & \overset{iid}{\sim} \; Beta(1, \theta) \\
  \phi_i & \overset{iid}{\sim} \; G_0
  \end{array}\]</p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-8" style="background:;">
  <hgroup>
    <h2>Animation of CRP</h2>
  </hgroup>
  <article data-timings="">
    <!-- <center>![CRP](figure/example_1.gif)</center> -->

<p><center><img width=500px height=500px src="figure/example_1.gif"></img></center></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-9" style="background:;">
  <hgroup>
    <h2>MCMC &amp; Gibbs Sampler</h2>
  </hgroup>
  <article data-timings="">
    <p><strong>Gibbs Sampler:</strong> also called alternating conditional sampling. Each iteration draws each subset conditional on the value of all the others \((X = (X_1, \cdots , X_d))\).</p>

<ol>
<li>Starts from an arbitrary state \(\mathbf{X}^{(0)}=\mathbf{x}^{(0)}\)</li>
<li>Moves with transition probability density: \[\mathbf{K}_G(\bf{x, y})=\prod^d_{\ell=1}\pi(y_\ell|\mathbf{y}_{1 : \ell -1}, \mathbf{x}_{\ell+1 : d})\]</li>
<li><p>Sample next state \(\mathbf{X}^{(m)}\) from \(K_G(\mathbf{X}^{(m-1)}, \mathbf{y})\)</p></li>
<li><p>Sub-steps(\(\ell\)-th): Sample \(\mathbf{X}^{(m)}_\ell\) from \[\pi(x|\mathbf{X}^{(m)}_{1 : \ell -1}, \mathbf{X}^{(m-1)}_{\ell+1 : d})\] </p></li>
</ol>

<style>
div.footnotes {
  position: absolute;
  bottom: 0;
  margin-bottom: 10px;
  width: 80%;
  font-size: 0.6em;
}
</style>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>

<script>
  $(document).ready(function() {
    $('slide:not(.backdrop):not(.title-slide)').append('<div class=\"footnotes\">');

    $('footnote').each(function(index) {
      var text  = $(this).html();
      var fnNum = (index+1).toString().sup();
      $(this).html(text + fnNum);

      var footnote   = fnNum + ': ' + $(this).attr('content') + '<br/>';
      var oldContent = $(this).parents('slide').children('div.footnotes').html();
      var newContent = oldContent + footnote;
      $(this).parents('slide').children('div.footnotes').html(newContent);
    });
  });
</script>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-10" style="background:;">
  <hgroup>
    <h2>DPMM &amp; Gibbs Sampler Algorithm</h2>
  </hgroup>
  <article data-timings="">
    <style>
div.footnotes {
  position: absolute;
  bottom: 0;
  margin-bottom: 10px;
  width: 80%;
  font-size: 0.6em;
}
</style>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>

<script>
  $(document).ready(function() {
    $('slide:not(.backdrop):not(.title-slide)').append('<div class=\"footnotes\">');

    $('footnote').each(function(index) {
      var text  = $(this).html();
      var fnNum = (index+1).toString().sup();
      $(this).html(text + fnNum);

      var footnote   = fnNum + ': ' + $(this).attr('content') + '<br/>';
      var oldContent = $(this).parents('slide').children('div.footnotes').html();
      var newContent = oldContent + footnote;
      $(this).parents('slide').children('div.footnotes').html(newContent);
    });
  });
</script>

<p>Simple Mixture Model: \[\begin{array} {l}
\mathbf{y}_i|\mathbf{\theta}_{i} \sim \mathcal{N}(\mathbf{\theta}_i, 1) \\
\theta_i \sim DP(\alpha, G_0) \\
G_0 \sim \mathcal{N}(0,2) 
\end{array}\]</p>

<p>In order to implement, explicit expression is <footnote content="Neal, R. M. (2000)."> needed </footnote>: \[\theta^t_{i}|\theta^t_{-i},y_i \sim \sum_{j\ne i} b_i F(y_i, \theta^t_j) \delta(\theta^t_j) + b_i \alpha \bigg[\int F(y_i, \theta)G_0(\theta)\bigg] H_i\] </p>

<p>\[b_i=\frac{1}{\sum_{j\ne i}F(y_i, \theta_j) + \alpha \int F(y_i, \theta)G_0(\theta)}\]</p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-11" style="background:;">
  <hgroup>
    <h2>DPMM &amp; Gibbs Sampler Algorithm</h2>
  </hgroup>
  <article data-timings="">
    <p><br> </p>

<ul>
<li><p>Likelihood function: \(F(y_i|\theta_i) = \frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}(y_i - \theta_i)^2}\)</p></li>
<li><p>Posterior distribution \(H_i = p(\theta|y_i)= \frac{F(y_i|\theta)G_0(\theta)}{\int{F(y_i|\theta)G_0(\theta)}}= \frac{1}{\sqrt{2\pi}\sqrt{2/3}}e^{\frac{(\theta - \frac{2}{3}y_i)^2}{2  (2/3)}}\)</p></li>
<li><p>\(\int{F(y_i|\theta)G_0(\theta)} = \frac{1}{\sqrt{6\pi}}e^{\frac{1}{6}(y_i)^2}\)</p></li>
<li><p>or another simple way: \(\Big(= \frac{F(y_i|\theta)G_0(\theta)}{H_i(\theta|y_i)}\Big)\)</p></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-12" style="background:;">
  <hgroup>
    <h2>Conjugate Prior is important</h2>
  </hgroup>
  <article data-timings="">
    <p>If the posterior distributions \(p(\theta|y)\) are in the <strong>same family as the prior probability distribution</strong> \(p(\theta)\) , the prior and posterior are then called conjugate distributions, and the prior is called <strong>a conjugate prior</strong> for the likelihood function.</p>

<p><strong>Model parameter</strong> \(\mathbf{\mu}\): mean of Normal with known variance \(\Sigma\). </p>

<p>Prior of \(\mathbf{\mu}\) is \(\mathcal{N}(\mathbf{\mu_0}, \Sigma_0)\)</p>

<p>By derivation, posterior distribution is :</p>

<p>\[\mathcal{N}\Bigg(\Bigg(\Sigma^{-1}_0+\Sigma^{-1} \Bigg)^{-1} \Bigg(\Sigma^{-1}_0\mathbf{\mu_0}+\Sigma^{-1}\mathbf{y}\Bigg),\Bigg(\Sigma^{-1}_0+\Sigma^{-1} \Bigg)^{-1}\Bigg)\]</p>

<!-- --- -->

<!-- ## DPMM & Gibbs Sampler Algorithm -->

<!-- The conditional distribution for Gibbs sampling is as following:  -->

<!-- $$\begin{array} -->

<!-- {rl} -->

<!-- \theta^t_{i}|\theta^t_{-i},y_i \sim & \sum_{j\ne i} q_{i,j} \delta(\theta^t_j) + r_i H_i \\ -->

<!-- q_{i,j} =                           & b_i F(y_i, \theta_j) \\ -->

<!-- r_i =                               & b_i \alpha \int F(y_i, \theta)G_0(\theta) \\ -->

<!-- \text{where } b_i \text{ satisfied}                                & \sum_{j\ne i}q_{i,j} + r_i = 1 -->

<!-- \end{array}$$ -->

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-13" style="background:;">
  <hgroup>
    <h2>DPMM &amp; Gibbs Sampler Algorithm</h2>
  </hgroup>
  <article data-timings="">
    <p>\[\begin{array}
{ll}
\hline
\textbf{Algorithm:} & \text{Gibbs Sampler for DPMM}  \\
\hline
1.\mathbf{Input:}   & \mathbf{y} \in \mathbb{R}^n,\;  \\
    & \theta^{(0)}_i \in (0,1), i=1,\cdots, n \\
    & \text{or} \;\theta^{(0)}_i = 0, i=1,\cdots, n \\
2. \mathbf{Repeat:} & (1) \;  q^*_{i,j} =  F(y_i, \theta^{(m)}_i) \\
                    & (2) \;  r^*_{i} = \alpha \int F(y_i, \theta^{(m)}_i) d G_0(\theta^{(m)}_i) \\
                    & (3) \;  b_{i} = 1/(\sum^n_{j=1} q^*_{i,j} + r^*_{i} ) \\
                    & (4) \;  \text{Draw} \; \theta^{(m)}_{i}|\theta^{(m)}_{-i,y_i} \sim \sum_{j\ne i} b_i q^*_{i,j} \delta(\theta^{(m)}_j) + b_i r^*_i H_i \\
                    & (5) \;  \text{Update} \; i=1, \cdots, n \\
3. \mathbf{Deliver:} & \hat\theta = \theta^{(m)} \\
\hline
\end{array}\]</p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-14" style="background:;">
  <hgroup>
    <h2>Convergency of one Markov chains</h2>
  </hgroup>
  <article data-timings="">
    <p>Start from a state with all <em>same</em> values:</p>

<p><br><br></p>

<p><center><img width=300px height=300px src="Example/gibbs01.png" align="left"></img>
<img width=300px height=300px src="Example/example_1.gif" align="center"></img>
<img width=300px height=300px src="Example/gibbs17.png" align="right"></img>
</center></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-15" style="background:;">
  <hgroup>
    <h2>Convergency of one Markov chains</h2>
  </hgroup>
  <article data-timings="">
    <p>Start from a state with all <em>different</em> values:</p>

<p><br><br></p>

<p><center><img width=300px height=300px src="Example/gibbs_Diff01.png" align="left"></img>
<img width=300px height=300px src="Example/example_2.gif" align="center"></img>
<img width=300px height=300px src="Example/gibbs_Diff17.png" align="right"></img>
</center></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-16" style="background:;">
  <hgroup>
    <h2>Convergency of Algorithm</h2>
  </hgroup>
  <article data-timings="">
    <p>Average total number of clusters \((K_n)\) v.s iteration times \((M)\) of Gibbs Sampler</p>

<p>\((n=1000, M\in (1,2,7,20,54,148,403))\)</p>

<p><img src="figure/unnamed-chunk-1-1.png" title="plot of chunk unnamed-chunk-1" alt="plot of chunk unnamed-chunk-1" style="display: block; margin: auto;" /></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-17" style="background:;">
  <hgroup>
    <h2>Convergency of Algorithm</h2>
  </hgroup>
  <article data-timings="">
    <p>Histogram of 100 replications for every given M:</p>

<!-- <center>![Convergency of Algorithm](figure/Covg_M.png) -->

<p><center><img width=600px height=600px src="figure/Covg_M.png"></img></center></p>

<ul>
<li>Total number of clusters approach the truth (15) when M increases</li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-18" style="background:;">
  <hgroup>
    <h2>Inference of cluster center</h2>
  </hgroup>
  <article data-timings="">
    <p>Centers of clusters might be of interest to you. </p>

<p><center><img width=400px height=400px src="figure/2BestGibbs.png" align="left"></img>
<img width=400px height=400px src="figure/BestGibbs.png" align="right"></img>
</center></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-19" style="background:;">
  <hgroup>
    <h2>Inference of cluster center</h2>
  </hgroup>
  <article data-timings="">
    <p>Animation of Centers of each cluster (100 simulation): </p>

<p><center><img width=400px height=400px src="figure/AnimatedGibbsCenter.gif"></img></center></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-20" style="background:;">
  <hgroup>
    <h2>DPMM &amp; Gibbs Sampler Algorithm</h2>
  </hgroup>
  <article data-timings="">
    <p>2D Simple Mixture Model: \[\begin{array} {rl}
\bigg(\begin{array}{c}y_{i,1}\\ y_{i,2}\\ \end{array}\bigg)|\bigg(\begin{array}{c} \theta_{i,1}\\ \theta_{i,2}\\ \end{array}\bigg) & \sim \mathcal{N}\bigg(\bigg(\begin{array}{c} \theta_{i,1}\\ \theta_{i,2}\\ \end{array}\bigg), \bigg(\begin{array}{cc}\sigma^2 & \\ & \sigma^2\\ \end{array}\bigg)\bigg) \\
\bigg(\begin{array}{c}\theta_{i,1}\\ \theta_{i,2}\\ \end{array}\bigg) & \sim DP(\alpha, G_0) \\
G_0 & \sim \mathcal{N}\bigg(\bigg(\begin{array}{c}0\\ 0\\ \end{array}\bigg), \bigg(\begin{array}{cc}\sigma^2_0 & \\ & \sigma^2_0\\ \end{array}\bigg)\bigg)
\end{array}\]</p>

<ul>
<li><p>Likelihood function: \(F\bigg(\bigg(\begin{array}{c}y_{i,1}\\ y_{i,2}\\ \end{array}\bigg)|\bigg(\begin{array}{c} \theta_{i,1}\\ \theta_{i,2}\\ \end{array}\bigg)\bigg) = \frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}(\mathbf{y_{i\cdot}} - \theta_{i\cdot})^2}\)</p></li>
<li><p>Posterior distribution \(H_i \sim \mathcal{N}\bigg(\frac{\sigma^2_0}{\sigma^2_0+\sigma^2}\bigg(\begin{array}{c}y_{i,1}\\ y_{i,2}\\ \end{array}\bigg), \frac{\sigma^2_0\sigma^2}{\sigma^2_0+\sigma^2}\bigg(\begin{array}{cc}1 & \\ & 1\\ \end{array}\bigg)\bigg)\) </p></li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-21" style="background:;">
  <hgroup>
    <h2>Gibbs Sampler results for 2D DPMM</h2>
  </hgroup>
  <article data-timings="">
    <p>Underlying clusters and estimated clusters from Gibbs Sample <a href="https://github.com/XiaoruiZhu/DPMM/blob/master/codes/DPMM_2D.R">(Algorithm for this 2D DPMM)</a></p>

<p><center><img width=450px height=400px src="figure/2D_Clusters_T.png" align="left"></img>
<img width=500px height=500px src="figure/2D_Clusters_Est1.png" align="right"></img>
</center></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-22" style="background:;">
  <hgroup>
    <h2>Gibbs Sampler results for 2D DPMM</h2>
  </hgroup>
  <article data-timings="">
    <p>Underlying clusters and estimated clusters from Gibbs Sample 
<br></p>

<p><center><img width=450px height=400px src="figure/2D_Clusters_T.png" align="left"></img>
<img width=500px height=500px src="figure/2D_Clusters_Est2.png" align="right"></img>
</center></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-23" style="background:;">
  <hgroup>
    <h2>Gibbs Sampler results for 2D DPMM</h2>
  </hgroup>
  <article data-timings="">
    <p>Underlying clusters and estimated clusters from Gibbs Sample 
<br> </p>

<p><center><img width=450px height=400px src="figure/2D_Clusters_T.png" align="left"></img>
<img width=500px height=500px src="figure/2D_Clusters_Est3.png" align="right"></img>
</center></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-24" style="background:;">
  <hgroup>
    <h2>Gibbs Sampler results for 2D DPMM</h2>
  </hgroup>
  <article data-timings="">
    <p>Underlying clusters and estimated clusters from Gibbs Sample 
<br> </p>

<p><center><img width=450px height=400px src="figure/2D_Clusters_T.png" align="left"></img>
<img width=500px height=500px src="figure/2D_Clusters_Est4.png" align="right"></img>
</center></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-25" style="background:;">
  <hgroup>
    <h2>Gibbs Sampler results for 2D DPMM</h2>
  </hgroup>
  <article data-timings="">
    <p>Underlying clusters and estimated clusters from Gibbs Sample 
<br> </p>

<p><center><img width=500px height=500px src="figure/2D_Clusters_animation.gif"></img>
</center></p>

  </article>
  <!-- Presenter Notes -->
</slide>

<slide class="" id="slide-26" style="background:;">
  <hgroup>
    <h2>Take Aways</h2>
  </hgroup>
  <article data-timings="">
    <p><br> <br> </p>

<ul>
<li>In 1D base measure setting, Algorithm converge very quick</li>
<li>Starting from all same initialization performs better </li>
<li>In 1D base measure, when \(M>50\), total number of cluster from Gibbs Sampler is acceptable, but it&#39;s not ture in 2D base measure </li>
</ul>

  </article>
  <!-- Presenter Notes -->
</slide>

    <slide class="backdrop"></slide>
  </slides>
  <div class="pagination pagination-small" id='io2012-ptoc' style="display:none;">
    <ul>
      <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=1 title='NA'>
         1
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=2 title='Storyline'>
         2
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=3 title='Motivation'>
         3
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=4 title='Motivation'>
         4
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=5 title='Motivation'>
         5
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=6 title='Motivation'>
         6
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=7 title='Dirichlet Process Mixture Model'>
         7
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=8 title='Animation of CRP'>
         8
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=9 title='MCMC &amp; Gibbs Sampler'>
         9
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=10 title='DPMM &amp; Gibbs Sampler Algorithm'>
         10
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=11 title='DPMM &amp; Gibbs Sampler Algorithm'>
         11
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=12 title='Conjugate Prior is important'>
         12
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=13 title='DPMM &amp; Gibbs Sampler Algorithm'>
         13
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=14 title='Convergency of one Markov chains'>
         14
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=15 title='Convergency of one Markov chains'>
         15
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=16 title='Convergency of Algorithm'>
         16
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=17 title='Convergency of Algorithm'>
         17
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=18 title='Inference of cluster center'>
         18
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=19 title='Inference of cluster center'>
         19
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=20 title='DPMM &amp; Gibbs Sampler Algorithm'>
         20
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=21 title='Gibbs Sampler results for 2D DPMM'>
         21
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=22 title='Gibbs Sampler results for 2D DPMM'>
         22
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=23 title='Gibbs Sampler results for 2D DPMM'>
         23
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=24 title='Gibbs Sampler results for 2D DPMM'>
         24
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=25 title='Gibbs Sampler results for 2D DPMM'>
         25
      </a>
    </li>
    <li>
      <a href="#" target="_self" rel='tooltip' 
        data-slide=26 title='Take Aways'>
         26
      </a>
    </li>
  </ul>
  </div>  <!--[if IE]>
    <script 
      src="http://ajax.googleapis.com/ajax/libs/chrome-frame/1/CFInstall.min.js">  
    </script>
    <script>CFInstall.check({mode: 'overlay'});</script>
  <![endif]-->
</body>
  <!-- Load Javascripts for Widgets -->
  <script src="libraries/widgets/bootstrap/js/bootstrap.min.js"></script>
<script src="libraries/widgets/bootstrap/js/bootbox.min.js"></script>
<script src="libraries/widgets/quiz/js/jquery.quiz.js"></script>
<script src="libraries/widgets/quiz/js/mustache.min.js"></script>
<script src="libraries/widgets/quiz/js/quiz-app.js"></script>
<script src="libraries/widgets/interactive/js/ace/js/ace.js"></script>
<script src="libraries/widgets/interactive/js/opencpu-0.5.js"></script>
<script src="libraries/widgets/interactive/js/interactive.js"></script>

  <!-- MathJax: Fall back to local if CDN offline but local image fonts are not supported (saves >100MB) -->
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        processEscapes: true
      }
    });
  </script>
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <!-- <script src="https://c328740.ssl.cf1.rackcdn.com/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script> -->
  <script>window.MathJax || document.write('<script type="text/x-mathjax-config">MathJax.Hub.Config({"HTML-CSS":{imageFont:null}});<\/script><script src="libraries/widgets/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"><\/script>')
</script>
<script>  
  $(function (){ 
    $("#example").popover(); 
    $("[rel='tooltip']").tooltip(); 
  });  
  </script>  
  
  <script src="shared/shiny.js" type="text/javascript"></script>
  <script src="shared/slider/js/jquery.slider.min.js"></script>
  <script src="shared/bootstrap/js/bootstrap.min.js"></script>
  <link rel="stylesheet" href="shared/slider/css/jquery.slider.min.css"></link>
  
  <!-- LOAD HIGHLIGHTER JS FILES -->
  <script src="libraries/highlighters/highlight.js/highlight.pack.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
  <!-- DONE LOADING HIGHLIGHTER JS FILES -->
   
  </html>